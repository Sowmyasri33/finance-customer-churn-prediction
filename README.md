ğŸ“‰ğŸ” Customer Churn Prediction using ğŸ¤– Logistic Regression & XGBoost
This ğŸ“¦ repository contains a project focused on predicting customer churn ğŸ”„ in a banking environment using advanced machine learning techniques. The dataset contains customer information ğŸ§¾ including financial status, account activity, and demographics. Three models have been implemented â€” Logistic Regression (with 5ï¸âƒ£ and ğŸ”Ÿ features) and an optimized XGBoost classifier ğŸš€ â€” to identify customers who are likely to leave the bank ğŸ¦.

ğŸ“ Contents:
 logistic_regression_5_features.py â€” Logistic regression model using 5 features.
 logistic_regression_10_features.py â€” Enhanced logistic regression with 10 features and feature analysis.
 xgboost_model.py â€” Optimized XGBoost pipeline with outlier handling, SMOTE, PCA, and hyperparameter tuning.
 Churn_Modelling.csv â€” ğŸ“Š Dataset used for training and evaluation.
 README.md â€” This ğŸ“„ file, describing project structure and usage.
 requirements.txt â€” List of required libraries for the project.

ğŸŒŸ Project Overview
Churn prediction ğŸ” is a crucial aspect for customer-focused industries like banking ğŸ¦. By predicting which customers are at risk of leaving, institutions can take proactive actions ğŸ¯ to improve retention and customer satisfaction.

This project implements:
   ğŸ“Š Data preprocessing
   ğŸ” SMOTE for handling class imbalance
   âš™ï¸ Polynomial feature engineering
   ğŸ“ Outlier handling using IQR
   ğŸ” Feature scaling (Standard & Robust)
   âš™ï¸ PCA for dimensionality reduction
   ğŸ§  Model tuning using GridSearchCV

ğŸ”§ Steps Followed
 1)Data Loading and Cleaning
    Load and clean the dataset from Churn_Modelling.csv. Handle duplicates and missing values.
 2)Exploratory Data Analysis (EDA)
    Visualize feature distributions, correlation heatmaps, and outlier detection using boxplots ğŸ“¦.
 3)Feature Engineering
 4)Logistic regression uses polynomial interaction terms.
 5)XGBoost pipeline includes Label Encoding, PCA, and robust scaling for numerical features.
 6)Model Building
 7)Logistic Regression with 5 and 10 features.
 8)XGBoost with GridSearchCV-based hyperparameter tuning and SMOTE.
 9)Model Evaluation
 10)Evaluate using Accuracy âœ”ï¸, Precision ğŸ¯, Recall ğŸ”, F1 Score ğŸ“Š, and Confusion Matrix ğŸ”€.
 Feature Importance & PCA Analysis
 Understand which features or principal components impact churn predictions the most ğŸ’¥.


 ğŸ“Š Dataset
 ğŸ—‚ File: Churn_Modelling.csv
 ğŸ§¾ Rows: 10,000
 ğŸ¯ Target: Exited (1 = churned, 0 = retained)
 Features include: CreditScore, Age, Tenure, Balance, NumOfProducts, IsActiveMember, EstimatedSalary
 Categorical: Geography, Gender


ğŸ“Š Visualizations
  ğŸ”¥ Heatmaps showing correlation between features
  ğŸ“¦ Boxplots before and after outlier removal
  ğŸ” Confusion matrices for all models
  ğŸ“Š Feature importances from XGBoost (via PCA components)
